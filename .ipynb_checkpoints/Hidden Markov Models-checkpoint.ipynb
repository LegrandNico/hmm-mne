{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini forward algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(x_t) =  \\displaystyle\\sum\\limits_{x_{t-1}}P(x_t|x_ {t+1})P(x_{t-1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The influence of the initial states tend to decrease over time and the final distribution is mostly independent of the initial one. Most of the Markov processes are end up with stationary distributions, which is the case when it satisfy:\n",
    "\n",
    "$$P_\\infty(X) = P_{\\infty+1}(X) = \\displaystyle\\sum\\limits_xP_{t+1|t}(X|x)P_\\infty(X)$$\n",
    "\n",
    "In other words, no matter how many states we add past infinity, the probability distribution will remain unchanged.\n",
    "\n",
    "If we want to think intuitively about that, there is only two way for this markov process to produce a *Sunny* state:\n",
    "- It can go from a rainny state to a sunny one.\n",
    "- It can go from a sunny state to another sunny state.\n",
    "\n",
    "Written formally, this gives:\n",
    "\n",
    "$$P_\\infty(SUN) = P_{t+1|t}(SUN|SUN)P_\\infty(SUN)+P_{t+1|t}(SUN|RAIN)P_\\infty(RAIN)$$\n",
    "$$P_\\infty(RAIN) = P_{t+1|t}(RAIN|SUN)P_\\infty(SUN)+P_{t+1|t}(RAIN|RAIN)P_\\infty(RAIN)$$\n",
    "\n",
    "Based on the previous transition probability matrice, we get:\n",
    "\n",
    "$$P_\\infty(SUN) = 0.9 * P_\\infty(SUN)+0.3 * P_\\infty(RAIN)$$\n",
    "$$P_\\infty(RAIN) = 0.1 * P_\\infty(SUN)+0.7 * P_\\infty(RAIN)$$\n",
    "\n",
    "Using linear algebra, we can then express these relation, also specifying that the sum of the probabilities must equal 1:\n",
    "\n",
    "$$x = 0.9x + 0.3y$$\n",
    "$$y = 0.1x + 0.7y$$\n",
    "$$x + y = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.25])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solving linear equation\n",
    "a = np.array([[-0.1, 0.3], [1.1, 0.7]])\n",
    "b = np.array([0, 1])\n",
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://en.wikipedia.org/wiki/Hidden_Markov_model\n",
    "\n",
    "[2] CS188 Artificial Intelligence UC Berkeley, Spring 2013. Prof. Pieter Abbeel. Retrieved from: https://www.youtube.com/watch?v=9dp4whVQv5s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
